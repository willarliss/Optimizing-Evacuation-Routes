{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.pipeline import EntityRuler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "- [Function Definitions](#fdef)\n",
    "- [NLP Set-up](#NLP)\n",
    "- [Data Processing](#data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions\n",
    "<a id = \"fdef\"></a>\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processes a dataframe with a 'Text' row using spacy nlp\n",
    "# returns a copy of the dataframe with a new 'docs' column\n",
    "\n",
    "def get_docs(df, nlp):\n",
    "    new_df = df.copy()\n",
    "    len_df = len(df)\n",
    "    docs = []\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for text in df['Text']:\n",
    "        try:\n",
    "            doc = nlp(text.lower())\n",
    "        except:\n",
    "            doc = []\n",
    "        \n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print(f'nlp progress: {round(100.0 * count / len_df, 1)}%')\n",
    "        \n",
    "        docs.append(doc)\n",
    "    \n",
    "    new_df['docs'] = docs\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(df):\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    to_keep = []\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    row_counter = 0\n",
    "\n",
    "    for doc in new_df['docs']:\n",
    "        \n",
    "        if doc == []:\n",
    "            to_keep.append(False)\n",
    "            continue\n",
    "        \n",
    "        keep = False\n",
    "\n",
    "        for ent in doc.ents:\n",
    "            e = ent.label_\n",
    "            if(e == \"street\" or e == 'highway' or e == 'exit'):\n",
    "                keep = True\n",
    "                row_counter+=1\n",
    "                continue\n",
    "\n",
    "        to_keep.append(keep)\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    print(f\"Tried to find matches in {count} documents, found {row_counter} rows with matches.\")\n",
    "    \n",
    "    return new_df[to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function finds where the docs have our new entity types and creates new dataframe rows\n",
    "#that correspond to each entity type\n",
    "\n",
    "def make_street_cols(df):\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    streets = []\n",
    "    highways = []\n",
    "    exits = []\n",
    "    markers = []\n",
    "    \n",
    "    for doc in df['docs']:\n",
    "        doc_streets = []\n",
    "        doc_highways = []\n",
    "        doc_exits = []\n",
    "        doc_markers = []\n",
    "        \n",
    "        if(doc != []):\n",
    "            for ent in doc.ents:\n",
    "                if(ent.label_ == 'street'):\n",
    "                    doc_streets.append(ent.text)\n",
    "                elif(ent.label_ == 'highway'):\n",
    "                    doc_highways.append(ent.text)\n",
    "                elif(ent.label_ == 'exit'):\n",
    "                    doc_exits.append(ent.text)\n",
    "                elif(ent.label_ == 'marker'):\n",
    "                    doc_markers.append(ent.text)\n",
    "        \n",
    "        streets.append(doc_streets)\n",
    "        highways.append(doc_highways)\n",
    "        exits.append(doc_exits)\n",
    "        markers.append(doc_markers)\n",
    "    \n",
    "    new_df['streets'] = streets\n",
    "    new_df['highways'] = highways\n",
    "    new_df['exits'] = exits\n",
    "    new_df['markers'] = markers\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_road_info(df, nlp):\n",
    "    new_df = df.drop_duplicates().copy()\n",
    "    new_df = get_docs(new_df, nlp)\n",
    "    new_df = find_matches(new_df)\n",
    "    new_df = make_street_cols(new_df)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patterns for entity ruler\n",
    "\n",
    "street_suff = ['street', 'st', 'avenue', 'ave', 'boulevard', 'blvd', 'highway', 'hwy',\n",
    "              'circle', 'drive', 'lane', 'road', 'rd', 'way', 'place', 'court',\n",
    "              'parkway', 'pkwy', 'turnpike', 'tpke', 'trnpk', 'turnpk']\n",
    "\n",
    "street_pattern = {\n",
    "    'label' : \"street\",\n",
    "    'pattern': [\n",
    "        {\"POS\" : {\"IN\" : [\"NOUN\",\"PROPN\", \"ADJ\"]}},\n",
    "        {\"LOWER\" : {\"IN\" : street_suff }} ]\n",
    "}\n",
    "\n",
    "#matches strings that look like interstates, ie. I-5, I-15, I-345\n",
    "interstate_pattern = {\n",
    "    'label' : \"highway\",\n",
    "    'pattern' : [\n",
    "        {\"TEXT\" : {\"REGEX\" : \"[Ii]-\\d*\"}} ]\n",
    "}\n",
    "\n",
    "#matches strings that look like US highways, ie. US-123\n",
    "us_hwy_pattern = {    \n",
    "    'label' : \"highway\",\n",
    "    'pattern' : [\n",
    "        {\"TEXT\" : {\"REGEX\" : \"[Uu][Ss]-\\d*\"}} ]\n",
    "}\n",
    "\n",
    "#matches strings that look like other highway names, including 'US' without the dash\n",
    "oth_hwy_pattern = {    \n",
    "    'label' : \"highway\",\n",
    "    'pattern' : [\n",
    "        {'LOWER' : {\"IN\" : ['us', 'highway', 'hwy', 'route', 'rt', 'rte']}},\n",
    "        {\"LIKE_NUM\" : True} ]\n",
    "}\n",
    "\n",
    "#matches spans that look like exit ramp numbers\n",
    "exit_pattern = {\n",
    "    'label' : \"exit\",\n",
    "    'pattern' : [\n",
    "        {\"LOWER\" : \"exit\"},\n",
    "        {\"LIKE_NUM\" : True} ]\n",
    "}\n",
    "\n",
    "state_hwy_pattern = {\n",
    "    'label' : \"highway\",\n",
    "    'pattern' : [\n",
    "        {\"LOWER\" : {\"IN\" : ['la', 'fl', 'al', 'ga', 'nc', 'sc', 'ms']}},\n",
    "        {\"LIKE_NUM\" : True}\n",
    "    ]\n",
    "}\n",
    "\n",
    "#matches spans that look like mile markers\n",
    "marker_pattern = {\n",
    "    'label' : \"marker\",\n",
    "    'pattern' : [\n",
    "        {\"LOWER\" : \"mile\"},\n",
    "        {\"LOWER\" : {\"IN\" : [\"marker\", \"post\"]}}, {\"LIKE_NUM\" : True} ]\n",
    "}\n",
    "\n",
    "patterns = [street_pattern, interstate_pattern, us_hwy_pattern, state_hwy_pattern, oth_hwy_pattern, exit_pattern, marker_pattern]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler = EntityRuler(nlp)\n",
    "ruler.add_patterns(patterns)\n",
    "nlp.add_pipe(ruler, before = 'ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "<a id=\"data\"></a>\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('./tweets_data/lake_ch_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12749 entries, 0 to 12748\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   User       12749 non-null  object\n",
      " 1   Text       12729 non-null  object\n",
      " 2   Date       12749 non-null  object\n",
      " 3   Favorites  12749 non-null  int64 \n",
      " 4   Retweets   12749 non-null  int64 \n",
      " 5   Mentions   1367 non-null   object\n",
      " 6   HashTags   2835 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 697.3+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp progress: 8.6%\n",
      "nlp progress: 17.1%\n",
      "nlp progress: 25.7%\n",
      "nlp progress: 34.3%\n",
      "nlp progress: 42.9%\n",
      "nlp progress: 51.4%\n",
      "nlp progress: 60.0%\n",
      "nlp progress: 68.6%\n",
      "nlp progress: 77.2%\n",
      "nlp progress: 85.7%\n",
      "nlp progress: 94.3%\n",
      "Tried to find matches in 11637 documents, encountered 0 errors when assigning entities.\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tweets_df_streets = extract_road_info(tweets_df, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>HashTags</th>\n",
       "      <th>docs</th>\n",
       "      <th>streets</th>\n",
       "      <th>highways</th>\n",
       "      <th>exits</th>\n",
       "      <th>markers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OKDOT</td>\n",
       "      <td>EDMOND: The northbound I-35 off-ramp to Waterl...</td>\n",
       "      <td>2020-09-03 23:30:16+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#trucking</td>\n",
       "      <td>(edmond, :, the, northbound, i-35, off, -, ram...</td>\n",
       "      <td>[waterloo rd]</td>\n",
       "      <td>[i-35]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>183South</td>\n",
       "      <td>THUR (9/3) 8 p.m. to 6 a.m., US 183 southbound...</td>\n",
       "      <td>2020-09-03 23:00:51+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#atxtraffic</td>\n",
       "      <td>(thur, (, 9/3, ), 8, p.m., to, 6, a.m., ,, us,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[us 183]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>OKDOT</td>\n",
       "      <td>OKC: The following ramps will be closed Thursd...</td>\n",
       "      <td>2020-09-03 23:00:11+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@BNSFRailway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(okc, :, the, following, ramps, will, be, clos...</td>\n",
       "      <td>[63rd st]</td>\n",
       "      <td>[i-235, i-44, i-44, i-44, us-77, i-235]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>myBIGinsurance</td>\n",
       "      <td>Did you know that texting for five seconds whi...</td>\n",
       "      <td>2020-09-03 22:30:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(did, you, know, that, texting, for, five, sec...</td>\n",
       "      <td>[national highway]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>MBenoit52</td>\n",
       "      <td>Unbelievable. Just like Trump and his minions,...</td>\n",
       "      <td>2020-09-03 21:11:40+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(unbelievable, ., just, like, trump, and, his,...</td>\n",
       "      <td>[fifth avenue]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              User                                               Text  \\\n",
       "18           OKDOT  EDMOND: The northbound I-35 off-ramp to Waterl...   \n",
       "34        183South  THUR (9/3) 8 p.m. to 6 a.m., US 183 southbound...   \n",
       "35           OKDOT  OKC: The following ramps will be closed Thursd...   \n",
       "49  myBIGinsurance  Did you know that texting for five seconds whi...   \n",
       "91       MBenoit52  Unbelievable. Just like Trump and his minions,...   \n",
       "\n",
       "                         Date  Favorites  Retweets      Mentions     HashTags  \\\n",
       "18  2020-09-03 23:30:16+00:00          0         1           NaN    #trucking   \n",
       "34  2020-09-03 23:00:51+00:00          0         1           NaN  #atxtraffic   \n",
       "35  2020-09-03 23:00:11+00:00          0         0  @BNSFRailway          NaN   \n",
       "49  2020-09-03 22:30:00+00:00          0         0           NaN          NaN   \n",
       "91  2020-09-03 21:11:40+00:00          0         0           NaN          NaN   \n",
       "\n",
       "                                                 docs             streets  \\\n",
       "18  (edmond, :, the, northbound, i-35, off, -, ram...       [waterloo rd]   \n",
       "34  (thur, (, 9/3, ), 8, p.m., to, 6, a.m., ,, us,...                  []   \n",
       "35  (okc, :, the, following, ramps, will, be, clos...           [63rd st]   \n",
       "49  (did, you, know, that, texting, for, five, sec...  [national highway]   \n",
       "91  (unbelievable, ., just, like, trump, and, his,...      [fifth avenue]   \n",
       "\n",
       "                                   highways exits markers  \n",
       "18                                   [i-35]    []      []  \n",
       "34                                 [us 183]    []      []  \n",
       "35  [i-235, i-44, i-44, i-44, us-77, i-235]    []      []  \n",
       "49                                       []    []      []  \n",
       "91                                       []    []      []  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_streets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1160 entries, 125 to 12732\n",
      "Data columns (total 12 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   User       1160 non-null   object\n",
      " 1   Text       1160 non-null   object\n",
      " 2   Date       1160 non-null   object\n",
      " 3   Favorites  1160 non-null   int64 \n",
      " 4   Retweets   1160 non-null   int64 \n",
      " 5   Mentions   77 non-null     object\n",
      " 6   HashTags   715 non-null    object\n",
      " 7   docs       1160 non-null   object\n",
      " 8   streets    1160 non-null   object\n",
      " 9   highways   1160 non-null   object\n",
      " 10  exits      1160 non-null   object\n",
      " 11  markers    1160 non-null   object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 117.8+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets_df_streets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_streets.to_csv('tweets_data/tweets_df_extended.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x2be3dd8e808>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x2be199714c8>),\n",
       " ('entity_ruler', <spacy.pipeline.entityruler.EntityRuler at 0x2be3baae2c8>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x2be3b763a08>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(nlp, open('./models/tweet_nlp.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf, open('./models/RoadFinder.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
